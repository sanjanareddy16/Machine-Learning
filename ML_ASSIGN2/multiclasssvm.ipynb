{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed7c1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Linear SVM:\n",
      "Accuracy: 0.33\n",
      "Custom Polynomial SVM:\n",
      "Accuracy: 0.13\n",
      "sklearn Linear SVM:\n",
      "Accuracy: 0.97\n",
      "sklearn Polynomial SVM:\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SVM():\n",
    "    def __init__(self, kernel='linear', degree=3, C=1.0, tol=1e-3, max_iter=1000):\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        # Initialize alpha and bias\n",
    "        self.alpha = np.zeros(n_samples)\n",
    "        self.b = 0\n",
    "\n",
    "        # Training loop\n",
    "        num_changed_alphas = 0\n",
    "        examine_all = True\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            num_changed_alphas = 0\n",
    "\n",
    "            if examine_all:\n",
    "                # Loop over all training examples\n",
    "                for i in range(n_samples):\n",
    "                    num_changed_alphas += self.examine(i)\n",
    "            else:\n",
    "                # Loop over examples where alpha is not 0 and not C\n",
    "                non_bound_indices = np.where((self.alpha > 0) & (self.alpha < self.C))[0]\n",
    "                for i in non_bound_indices:\n",
    "                    num_changed_alphas += self.examine(i)\n",
    "\n",
    "            if examine_all:\n",
    "                examine_all = False\n",
    "            elif num_changed_alphas == 0:\n",
    "                examine_all = True\n",
    "\n",
    "        # Compute the bias\n",
    "        self.b = self._compute_bias()\n",
    "\n",
    "    def _kernel_function(self, x1, x2):\n",
    "        if self.kernel == 'linear':\n",
    "            return np.dot(x1, x2)\n",
    "        elif self.kernel == 'poly':\n",
    "            return (np.dot(x1, x2) + 1) ** self.degree\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel type\")\n",
    "\n",
    "    def examine(self, i2):\n",
    "        y2 = self.y[i2]\n",
    "        alpha2 = self.alpha[i2]\n",
    "        x2 = self.X[i2]\n",
    "        E2 = self.decision_function(x2) - y2\n",
    "\n",
    "       \n",
    "        if (y2 * E2 < -self.tol and alpha2 < self.C) or (y2 * E2 > self.tol and alpha2 > 0):\n",
    "            # Select i1 based on maximum error\n",
    "            if E2 > 0:\n",
    "                i1 = np.argmin(self.alpha)\n",
    "            else:\n",
    "                i1 = np.argmax(self.alpha)\n",
    "\n",
    "            if self.smo_step(i1, i2):\n",
    "                return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def smo_step(self, i1, i2):\n",
    "        if i1 == i2:\n",
    "            return 0\n",
    "\n",
    "        alpha1 = self.alpha[i1]\n",
    "        alpha2 = self.alpha[i2]\n",
    "        y1 = self.y[i1]\n",
    "        y2 = self.y[i2]\n",
    "        x1 = self.X[i1]\n",
    "        x2 = self.X[i2]\n",
    "\n",
    "        E1 = self.decision_function(x1) - y1\n",
    "        E2 = self.decision_function(x2) - y2\n",
    "\n",
    "        # Compute L and H, the bounds on alpha2\n",
    "        if y1 != y2:\n",
    "            L = max(0, alpha2 - alpha1)\n",
    "            H = min(self.C, self.C + alpha2 - alpha1)\n",
    "        else:\n",
    "            L = max(0, alpha1 + alpha2 - self.C)\n",
    "            H = min(self.C, alpha1 + alpha2)\n",
    "\n",
    "        if L == H:\n",
    "            return 0\n",
    "\n",
    "        k11 = self._kernel_function(x1, x1)\n",
    "        k22 = self._kernel_function(x2, x2)\n",
    "        k12 = self._kernel_function(x1, x2)\n",
    "\n",
    "        # Compute eta\n",
    "        eta = 2 * k12 - k11 - k22\n",
    "\n",
    "        if eta < 0:\n",
    "   \n",
    "            alpha2_new = alpha2 - y2 * (E1 - E2) / eta\n",
    "            alpha2_new = max(L, min(H, alpha2_new))\n",
    "\n",
    "            if abs(alpha2_new - alpha2) < 1e-5:\n",
    "                return 0\n",
    "\n",
    "  \n",
    "            alpha1_new = alpha1 + y1 * y2 * (alpha2 - alpha2_new)\n",
    "\n",
    "        \n",
    "            b1 = self.b - E1 - y1 * (alpha1_new - alpha1) * k11 - y2 * (alpha2_new - alpha2) * k12\n",
    "            b2 = self.b - E2 - y1 * (alpha1_new - alpha1) * k12 - y2 * (alpha2_new - alpha2) * k22\n",
    "\n",
    "            if 0 < alpha1_new < self.C:\n",
    "                self.b = b1\n",
    "            elif 0 < alpha2_new < self.C:\n",
    "                self.b = b2\n",
    "            else:\n",
    "                self.b = (b1 + b2) / 2\n",
    "\n",
    "           \n",
    "            self.alpha[i1] = alpha1_new\n",
    "            self.alpha[i2] = alpha2_new\n",
    "\n",
    "            return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            return np.sum(self.alpha * self.y * np.array([self._kernel_function(X, xi) for xi in self.X])) - self.b\n",
    "        else:\n",
    "            return np.sum(np.array([self.alpha * self.y * np.array([self._kernel_function(xi, xj) for xi in self.X]) for xj in X]) - self.b, axis=1)\n",
    "\n",
    "\n",
    "    def _compute_bias(self):\n",
    "\n",
    "        support_vector_indices = np.where((self.alpha > 0) & (self.alpha < self.C))[0]\n",
    "        \n",
    "     \n",
    "        if len(support_vector_indices) > 0:\n",
    "            i = support_vector_indices[0]\n",
    "            return self.y[i] - np.sum(self.alpha * self.y * np.array([self._kernel_function(self.X[i], xi) for xi in self.X])) + self.b\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            return np.sign(self.decision_function(X))\n",
    "        else:\n",
    "            return np.sign(self.decision_function(np.array(X)))\n",
    "\n",
    "class MultiSVM():\n",
    "    def __init__(self, kernel='linear', degree=3, C=1.0, tol=1e-3, max_iter=1000):\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.binary_classifiers = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.unique_classes = np.unique(y)\n",
    "        num_classes = len(self.unique_classes)\n",
    "\n",
    "      \n",
    "        for i in range(num_classes):\n",
    "            for j in range(i + 1, num_classes):\n",
    "              \n",
    "                class_mask = (y == self.unique_classes[i]) | (y == self.unique_classes[j])\n",
    "                X_binary = X[class_mask]\n",
    "                y_binary = y[class_mask]\n",
    "\n",
    "                binary_svm = SVM(kernel=self.kernel, degree=self.degree, C=self.C, tol=self.tol, max_iter=self.max_iter)\n",
    "                binary_svm.fit(X_binary, y_binary)\n",
    "\n",
    "                self.binary_classifiers.append(((self.unique_classes[i], self.unique_classes[j]), binary_svm))\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_samples = X.shape[0]\n",
    "        num_classes = len(self.unique_classes)\n",
    "        votes = np.zeros((num_samples, num_classes), dtype=int)\n",
    "\n",
    "        for binary_classes, binary_svm in self.binary_classifiers:\n",
    "            i, j = binary_classes\n",
    "            binary_predictions = binary_svm.predict(X)\n",
    "\n",
    "            for k in range(num_samples):\n",
    "                if binary_predictions[k] == 1:\n",
    "                    votes[k, i] += 1\n",
    "                else:\n",
    "                    votes[k, j] += 1\n",
    "\n",
    "   \n",
    "        multi_class_predictions = np.argmax(votes, axis=1)\n",
    "\n",
    "        return [self.unique_classes[i] for i in multi_class_predictions]\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom SVM with linear kernel\n",
    "custom_linear_svm = SVM(kernel='linear', C=1.0, tol=1e-3, max_iter=1000)\n",
    "custom_linear_svm.fit(X_train, y_train)\n",
    "y_pred_custom_linear = custom_linear_svm.predict(X_test)\n",
    "accuracy_custom_linear = accuracy_score(y_test, y_pred_custom_linear)\n",
    "print(\"Custom Linear SVM:\")\n",
    "print(f\"Accuracy: {accuracy_custom_linear:.2f}\")\n",
    "\n",
    "# Custom SVM with polynomial kernel\n",
    "custom_poly_svm = SVM(kernel='poly', degree=3, C=1.0, tol=1e-3, max_iter=1000)\n",
    "custom_poly_svm.fit(X_train, y_train)\n",
    "y_pred_custom_poly = custom_poly_svm.predict(X_test)\n",
    "accuracy_custom_poly = accuracy_score(y_test, y_pred_custom_poly)\n",
    "print(\"Custom Polynomial SVM:\")\n",
    "print(f\"Accuracy: {accuracy_custom_poly:.2f}\")\n",
    "\n",
    "# scikit-learn SVC with linear kernel\n",
    "sklearn_linear_svm = SVC(kernel='linear', C=1.0)\n",
    "sklearn_linear_svm.fit(X_train, y_train)\n",
    "y_pred_sklearn_linear = sklearn_linear_svm.predict(X_test)\n",
    "accuracy_sklearn_linear = accuracy_score(y_test, y_pred_sklearn_linear)\n",
    "print(\"sklearn Linear SVM:\")\n",
    "print(f\"Accuracy: {accuracy_sklearn_linear:.2f}\")\n",
    "\n",
    "# scikit-learn SVC with polynomial kernel\n",
    "sklearn_poly_svm = SVC(kernel='poly', degree=3, C=1.0)\n",
    "sklearn_poly_svm.fit(X_train, y_train)\n",
    "y_pred_sklearn_poly = sklearn_poly_svm.predict(X_test)\n",
    "accuracy_sklearn_poly = accuracy_score(y_test, y_pred_sklearn_poly)\n",
    "print(\"sklearn Polynomial SVM:\")\n",
    "print(f\"Accuracy: {accuracy_sklearn_poly:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2dd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
